{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation \n",
    "\n",
    "For this homework you will use sigmoid as an activation function. Think about the following questions (you do not have to hand in the answers, they are just for your own recap)\n",
    "\n",
    "- What is the purpose of an activation function in a NN in general?\n",
    "\n",
    "- What's the advantage of e.g. sigmoid over the step function (threshold function)?\n",
    "\n",
    "- How does sigmoid look like (the formula as well as the graph)?\n",
    "\n",
    "- What is the derivative of sigmoid?\n",
    "\n",
    "Implement a function sigmoid ( $\\mathrm{x}$ ) and a function sigmoidprime ( $\\mathrm{x}$ ) (the derivative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the activation functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"Function implements the sigmoid function\n",
    "        Args:\n",
    "            x (ndarray): Ndarray of values on which sigmoid should be applied\n",
    "        Returns:\n",
    "            sig (ndarray): Ndarray of resulting values\n",
    "    \"\"\"\n",
    "    sig = 1 / (1 + np.exp(-x))\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidprime(x):\n",
    "    \"\"\"Function implements the derivative of a sigmoid function and expects a numpy array as argument\n",
    "        Args:\n",
    "            x (ndarray): Ndarray of values on which the sigmoid derivative should be applied\n",
    "        Returns:\n",
    "            ds (ndarray): Ndarray of resulting values\n",
    "    \"\"\"\n",
    "    s = sigmoid(x)\n",
    "    ds = s*(1-s)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data set and target values\n",
    "\n",
    "The training data set will consist of possible inputs and their corresponding labels. We are training the network on logical gates (and, or, not and, not or, xor $==$ exclusive or). We will create the inputs and labels ourselves.\n",
    "\n",
    "What are possible inputs to the logical gates?\n",
    "\n",
    "For each of the logical gates you will need an array of labels $(=$ the true solution that the network is supposed to output), one corresponding to each input pair. ${ }^{2}$\n",
    "\n",
    "${ }^{1}$ The logical gates take as input two binary digits (either 1 or 0 ), with all possible combinations there should be 4 input pairs. Put them in a $2 \\mathrm{D}$ numpy array. (The shape of the array should be $(4,2))$\n",
    "\n",
    "${ }^{2}$ You will need 5 arrays for each type of gate containing 4 binary digits $(0$ or 1 corresponding to the input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "logical_inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "# targeted results\n",
    "t_and = np.array([0,0,0,1])\n",
    "t_or = np.array([0,1,1,1])\n",
    "t_nand = np.array([1,1,1,0])\n",
    "t_nor = np.array([1,0,0,0])\n",
    "t_xor = np.array([0,1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron class\n",
    "\n",
    "Our multilayer-Perceptron will consist of single Perceptrons. So we will need a class Perceptron.\n",
    "\n",
    "Think about what a Perceptron consists of. ${ }^{3}$\n",
    "\n",
    "When you create a Perceptron, it should receive an integer argument called input_units specifying how many weights are coming in to your Perceptron. In the beginning, random values should be assigned to the weights and the bias. ${ }^{4}$ Also assign the learning rate alpha $=1 .{ }^{5}$\n",
    "\n",
    "The Perceptron should have a function forward_step(self, inputs) that calculates the activation of the perceptron. Use sigmoid as activation function.\n",
    "\n",
    "Then you'll need a function update (self, delta) which updates the parameters. To do so, compute the gradients for weights and bias from the error term $\\delta$. (This error term will be passed to the function when the backpropagation of the parent class MLP() is called - see next section.\n",
    "\n",
    "Compute the gradients using:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_{i j}^{(l)}}=\\delta_{i}^{(l)} a_{j}^{(l-1)}\n",
    "$$\n",
    "\n",
    "And then update the parameters using:\n",
    "\n",
    "$$\n",
    "\\theta_{\\text {new }}=\\theta_{\\text {old }}-\\alpha \\nabla L_{\\theta}\n",
    "$$\n",
    "\n",
    "${ }^{3}$ weights and a bias\n",
    "\n",
    "${ }^{4}$ you can use np.random.randn() for that\n",
    "\n",
    "${ }^{5}$ All of this happens in the _init_. function. Make sure you define weights, bias, alpha with self. in the beginning so they can be accessed in all functions of the class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \"\"\"Single neuron handling its own weights and bias.\n",
    "        Instance Attributes:\n",
    "            weights (ndarray): weights coming into the perceptron\n",
    "            bias (float): additional bias weight\n",
    "            alpha (int): Learning rate\n",
    "        Methods:\n",
    "            __init__(self, input_units): Class constructor\n",
    "            forward_step(self, inputs): Calculates activation of the neuron\n",
    "            update(self, delta): Updates the weights\n",
    "    \"\"\"\n",
    "    def __init__(self, input_units):\n",
    "        \"\"\"Initialize a new neuron with its weights and bias.\n",
    "            Args:\n",
    "                input_units (int): Dimensionality of the data coming into this perceptron.\n",
    "                    In a network of perceptrons this basically represents the\n",
    "                    number of neurons in the layer before this neuron's layer or basically how many weights are coming in.\n",
    "                    Used for generating the perceptron's weights vector, which not only includes one weight per input\n",
    "                    but also an additional bias weight.\n",
    "        \"\"\"\n",
    "        # initializing as many random weights as given input_units \n",
    "        self.weights = np.random.randn(input_units)\n",
    "        \n",
    "        # its a single perceptron, so should have a single random bias. \n",
    "        self.bias = np.random.randn()\n",
    "        \n",
    "        # learning rate\n",
    "        self.alpha = 1\n",
    "        \n",
    "    def forward_step(self, inputs):\n",
    "        \"\"\"Function calculates the activation of the perceptron using sigmoid as activation function on the weighted sum.\n",
    "        Weighted sum is calculateed from the dot product of input and weights plus the bias.\n",
    "            Args:\n",
    "                self: gain access to all weights (and the bias) and the learning rate\n",
    "                inputs (ndarray): gathers all inputs\n",
    "            Returns:\n",
    "                float between 0 and 1 for the activation\n",
    "        \"\"\"\n",
    "        # gather the input\n",
    "        self.input = inputs\n",
    "        \n",
    "        # calculates the weighted sum after: weight = ( W dot X + b )  \n",
    "        self.weighted_sum = self.weights @ self.input  + self.bias \n",
    "        \n",
    "        # puts it through activation function sigma(weight) and returns the output\n",
    "        return sigmoid(self.weighted_sum)\n",
    "    \n",
    "    \n",
    "    def update(self, delta):\n",
    "        \"\"\" Computes the gradient for weights and bias from the error term delta, then updates the neurons weights accordingly.\n",
    "            Args:\n",
    "                self: gain access to all weights (and the bias) and the learning rate\n",
    "                delta (float): Error value passed during backpropagation\n",
    "        \"\"\"\n",
    "        # calculation of the gradient (â–½ L) = delta_of_next_neuron * output_of_corresponding_neuron \n",
    "        gradient =  delta * self.input\n",
    "        \n",
    "        # updating the weights according to the learning rate and calculated gradient\n",
    "        self.weights -= self.alpha * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "\n",
    "Further, we will need a class MLP() that can perform a forward and backprop-step. Initialize the MLP with $\\mathbf{1}$ hidden layer that has $\\mathbf{4}$ Perceptrons. Initialize $\\mathbf{1}$ output neuron$ { }^{7}$. Define the following functions of the class:\n",
    "\n",
    "- In the forward_step the inputs are passed through the network. ${ }^{8}$\n",
    "\n",
    "- In the backprop_step the parameters of the network are updated. ${ }^{9}$\n",
    "\n",
    "\n",
    "${ }^{7}$ It might make sense to also initialize a variable self. output to store the output.\n",
    "\n",
    "${ }^{8}$ First compute the activations for the hidden layer. (You might need to reshape the resulting array to feed it to the output neuron. Check np.reshape (arr, newshape $=(-1))$.)\n",
    "\n",
    "Then feed the activations of the hidden laver into the output laver. Store it in self. output.\n",
    "\n",
    "${ }^{9}$ That means, update the weights and the biases of the output neuron (first) and neurons in the hidden layers (afterwards). For that, first compute the error term $\\delta$ using this formula:\n",
    "\n",
    "$$\n",
    "\\delta_{i}^{(l)}=\\left\\{-\\left(t_{i}-y_{i}\\right) \\sigma^{\\prime}\\left(d_{i}^{(N)}\\right) \\text { if } l=N,\\left(\\sum_{k=1}^{m} \\delta_{k}^{(l+1)} w_{k i}^{(+1)}\\right) \\sigma^{\\prime}\\left(d_{i}^{(l)}\\right)\\right. \\text { else. }\n",
    "$$\n",
    "\n",
    "Then call the update (self, delta) function of the respective neuron and hand the delta over.\n",
    "\n",
    "(This is just a suggestion, there might be different solutions.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    \"\"\" Network of multiple perceptron layers.\n",
    "        Instance attributes:\n",
    "            h_layer (list of instances of Perceptron): hidden layer of the MLP\n",
    "            out_neuron (instance of Perceptron): output neuron\n",
    "            output (int): stores output of a layer (default 0)\n",
    "        Methods:\n",
    "            __init__(self): Class constructor\n",
    "            forward_step(self, inputs): Performs a forward step\n",
    "            backprop_step(self, inputs, target): Performs backpropagation step\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize a new network, made up of individual perceptron layers.\"\"\"\n",
    "        # initialize 1 hidden layer with 4 perceptrons\n",
    "        self.h_layer = [Perceptron(2), Perceptron(2), Perceptron(2), Perceptron(2)]\n",
    "        \n",
    "        # initialize the output neuron 4 types of combination \n",
    "        self.out_neuron = Perceptron(4)\n",
    "        \n",
    "        # initialize a variable self.output to store the output\n",
    "        self.output = 0\n",
    "    \n",
    "    def forward_step(self, inputs):\n",
    "        \"\"\"Performs a forward step: Computes activation of all neurons in the layer and feeds them to the output.\n",
    "            Args:\n",
    "                self: gain access to the layers of the MLP\n",
    "                inputs (ndarray): Input to the layer\n",
    "        \"\"\"\n",
    "        # create an empty list\n",
    "        activations = []\n",
    "        \n",
    "        # compute the activation for every neuron in hidden layer iteratively\n",
    "        for perceptron in self.h_layer:\n",
    "            # calls the forward step for each neuron (activation)\n",
    "            collect_activation = perceptron.forward_step(inputs)\n",
    "            # stores activation in a list\n",
    "            activations.append(collect_activation)\n",
    "        \n",
    "        # convert the activations list into an array and reshapes it to a single vector\n",
    "        activations = np.reshape(np.array(activations), newshape = (-1))\n",
    "        \n",
    "        # recall function for the output layer with the activation vector as new input to get final output\n",
    "        self.output = self.out_neuron.forward_step(activations)\n",
    "        \n",
    "    \n",
    "    def backprop_step(self, inputs, target):\n",
    "        \"\"\"Performs a backpropagation step where it calculates the error rate delta for each perceptron\n",
    "        and adapts the weights by calling on Perceptron.update()\n",
    "            self: gain access to the layers of the MLP\n",
    "            inputs (ndarray): takes inputs to the MLP\n",
    "            target (ndarray): target values\n",
    "        \"\"\"\n",
    "        ## Step 1: backpropagation on the output neurons (layer == N) \n",
    "        \n",
    "        # calculate the error rate delta for the output neuron\n",
    "        # formula: delta(output) = (output - target value) * sigmoid'(weighted sum)\n",
    "        delta_output = (self.output - target) * sigmoidprime(self.out_neuron.weighted_sum)\n",
    "        \n",
    "        # update the weights with the calculated error rate\n",
    "        self.out_neuron.update(delta_output)\n",
    "        \n",
    "        \n",
    "        ## Step 2: hidden neurons\n",
    "\n",
    "        # creating empty list for storing the delta values of the hidden layer\n",
    "        delta_hidden = []\n",
    "        \n",
    "        # for each perceptron in the hidden layer apply\n",
    "        # formula: delta(hidden) = delta_j * sigmoid'(weighted sum) * sum_of_weights\n",
    "        for index, perceptron in enumerate(self.h_layer):\n",
    "            # compute the delta value and add it to the list (first itter = calculate the output neurons delta) \n",
    "            collect_delta = delta_output * sigmoidprime(perceptron.weighted_sum) * self.out_neuron.weights[index]\n",
    "            delta_hidden.append(collect_delta)\n",
    "            # update the weights for the next backward neuron\n",
    "            perceptron.update(delta_hidden[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "As a loss function for training, we will use the squared error $(t-y)^{2}$. This loss is the sigmoid output vs. the target (=label in dataset). But as discussed in the lecture, we want to introduce an additional measurement of the performance of the network: This is the accuracy measure. While the loss compares the distance of our network to the ground truth, the accuracy makes a less qualitative statement about the performance of our network, but quantitatively tells us how our network is doing. To do so, we introduce a threshold, in our case we use $0.5$ and define that if the network outputs a value bigger than $0.5$ and the target is 1 , it counts as a correct classification. If target is 0 a correct classification will be a value smaller than $0.5$ respectively. The accuaracy is then defined as the ratio of correct classification vs total classifications performed\n",
    "\n",
    "The training procedure thus should consist of the following steps:\n",
    "\n",
    "1. Create an instance of an MLP class.\n",
    "\n",
    "2. Train the instance for 1000 epochs.\n",
    "\n",
    "a) In each epoch, loop over each point in your dataset once.\n",
    "\n",
    "i. For each data point, perform a forward and a backward step.\n",
    "\n",
    "ii. Record the accuracy and the loss for each point.\n",
    "\n",
    "For the purpose of visualization and also to monitor the performance of your network, you should keep track of the epochs and the average loss and accuracy for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instance of the MLP class\n",
    "mlp = MLP()\n",
    "\n",
    "# initialize lists to store performance and declare threshold and epochs to train to\n",
    "accuracies = []\n",
    "losses = []\n",
    "epochs = []\n",
    "threshold = 0.5\n",
    "epoch = 1000\n",
    "\n",
    "for index in range(epoch):\n",
    "    # keep track of the steps and start all tracking at 0\n",
    "    epochs.append(index)\n",
    "    my_accuracy = 0\n",
    "    my_loss = 0\n",
    "    \n",
    "    # iterate over the inputs and corresponding target values\n",
    "    for number in range(4):\n",
    "        input = logical_inputs[number]\n",
    "        target = t_xor[number]\n",
    "\n",
    "        mlp.forward_step(input)\n",
    "        mlp.backprop_step(input, target)\n",
    "\n",
    "        # checking if the output and target values match\n",
    "        my_accuracy += int(int(mlp.output >= threshold) == target)\n",
    "\n",
    "        # calculate the loss with the squared error = (t-y)^2\n",
    "        my_loss += (target - mlp.output) ** 2\n",
    "\n",
    "    accuracy = my_accuracy/4\n",
    "    accuracies.append(accuracy)\n",
    "    losses.append(my_loss/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "  Visualize the training progress using matplotlib. Create one graph with the epochs on the $x$-axis and the average loss per epoch on the $y$-axis. Do the same for the average accuracy per epoch.\n",
    "\n",
    "If your MLP trained correctly, the loss should come down to zero and the accuracy should go up to 1 in most cases. Due to random weight initialization the accuracy might not reach 1 sometimes. In that case just rerun the MLP initialization and the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "# plot the accuracy vs the epoch\n",
    "plt.title(\"accuracy vs epoch\")\n",
    "plt.plot(epochs,accuracies)\n",
    "plt.xlabel(\"step size\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "\n",
    "# plot the loss vs the epoch\n",
    "plt.figure()\n",
    "\n",
    "plt.title(\"loss vs epoch\")\n",
    "plt.plot(epochs,losses)\n",
    "plt.xlabel(\"step size\")\n",
    "plt.ylabel(\"loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
