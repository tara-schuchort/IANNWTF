{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IANNWTF_09.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Necessary imports"
      ],
      "metadata": {
        "id": "F98heQce0505"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from re import split\n",
        "import os\n",
        "import urllib\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "from tensorflow.keras.layers import BatchNormalization, Reshape, Conv2DTranspose, Flatten, Conv2D, Dense, Dropout"
      ],
      "metadata": {
        "id": "sV3AbxyUxV9h"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the data"
      ],
      "metadata": {
        "id": "d4CGPKyg02TQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Loading the data set directly from google\n",
        "        Returns:\n",
        "            data: processed dataset\n",
        "    \"\"\"\n",
        "\n",
        "    # load images restricted to one category (candles)\n",
        "    categories = [line.rstrip(b'\\n') for line in urllib.request.urlopen('https://raw.githubusercontent.com/googlecreativelab/quickdraw-dataset/master/categories.txt')]\n",
        "    category = 'candle'\n",
        "\n",
        "    # Creates a folder to download the original drawings into.\n",
        "    if not os.path.isdir('npy_files'):\n",
        "        os.mkdir('npy_files')\n",
        "\n",
        "    url = f'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/{category}.npy'\n",
        "    urllib.request.urlretrieve(url, f'npy_files/{category}.npy')\n",
        "\n",
        "    images = np.load(f'npy_files/{category}.npy')\n",
        "    print(f'{len(images)} images to train on')\n",
        "\n",
        "    train_imgs = images[:30000]\n",
        "    valid_imgs = images[30000:40000]\n",
        "    test_imgs = images[40000:50000]\n",
        "\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices(train_imgs)\n",
        "    valid_ds = tf.data.Dataset.from_tensor_slices(valid_imgs)\n",
        "    test_ds = tf.data.Dataset.from_tensor_slices(test_imgs)\n",
        "    \n",
        "    # performing preprocessing steps\n",
        "    train_ds = data_pipeline(train_ds)\n",
        "    valid_ds = data_pipeline(valid_ds)\n",
        "    test_ds = data_pipeline(test_ds)\n",
        "\n",
        "    return train_ds, valid_ds, test_ds\n",
        "\n",
        "def data_pipeline(data):\n",
        "    \"\"\" Describtion here\n",
        "    Args:\n",
        "        data:\n",
        "    Return:\n",
        "        data:\n",
        "    \"\"\"\n",
        "    # casting and reshaping\n",
        "    data = data.map(lambda image: (tf.cast(image, tf.float32)))\n",
        "    data = data.map(lambda image: (tf.reshape(image,[28,28,1])))\n",
        "    # normalization, brings image values from range [0, 255] to [-1, 1]\n",
        "    data = data.map(lambda image: ((image/128)-1))\n",
        "\n",
        "    #cache progress in memory, as there is no need to redo it\n",
        "    data = data.cache()\n",
        "\n",
        "    #shuffle, batch, prefetch\n",
        "    data = data.shuffle(2000)\n",
        "    data = data.batch(64)\n",
        "    data = data.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "F3QbQpLYw5P3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAN Model"
      ],
      "metadata": {
        "id": "Vj9gcKcd1StC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discriminator"
      ],
      "metadata": {
        "id": "sq1EtK0X1ddj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Descriminator(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Descriminator, self).__init__()\n",
        "\n",
        "        self._conv1 = Conv2D(filters=64, kernel_size=5, strides=2, padding=\"same\")\n",
        "        self._drop1 = Dropout(0.3)\n",
        "\n",
        "        self._conv2 = Conv2D(filters=128, kernel_size=5, strides=2, padding=\"same\")\n",
        "        self._drop2 = Dropout(0.3)\n",
        "\n",
        "        self._flatten = Flatten()\n",
        "        self._dense = Dense(1)\n",
        "\n",
        "    def call(self, x, for_training=None):\n",
        "\n",
        "        x = self._conv1(x, training=for_training)\n",
        "        x = tf.nn.leaky_relu(x)\n",
        "        x = self._drop1(x, training=for_training)\n",
        "\n",
        "        x = self._conv2(x, training=for_training)\n",
        "        x = tf.nn.leaky_relu(x)\n",
        "        x = self._drop2(x, training=for_training)\n",
        "\n",
        "        x = self._flatten(x, training=for_training)\n",
        "        x = self._dense(x, training=for_training)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "S9iVat8A1h0B"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator"
      ],
      "metadata": {
        "id": "juOaqli21fkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self._dense = Dense(7*7*8)\n",
        "\n",
        "        self._bn1 = BatchNormalization()\n",
        "        self._convt1 = Conv2DTranspose(filters=128, kernel_size=5, strides=1, padding=\"same\")\n",
        "\n",
        "        self._bn2 = BatchNormalization()\n",
        "        self._convt2 = Conv2DTranspose(filters=64, kernel_size=5, strides=2, padding=\"same\")\n",
        "\n",
        "        self._bn3 = BatchNormalization()\n",
        "        self._out = Conv2DTranspose(filters=1, kernel_size=5, strides=2, padding=\"same\", activation=\"tanh\")\n",
        "\n",
        "    def call(self, x, for_training=None):\n",
        "        x = self._dense(x, training=for_training)\n",
        "\n",
        "        x = self._bn1(x, training=for_training)\n",
        "        x = tf.nn.leaky_relu(x)\n",
        "        x = tf.reshape(x, (64,7,7,8))\n",
        "        x = self._convt1(x, training=for_training)\n",
        "\n",
        "        x = self._bn2(x, training=for_training)\n",
        "        x = tf.nn.leaky_relu(x)\n",
        "        x = self._convt2(x, training=for_training)\n",
        "        \n",
        "        x = self._bn3(x, training=for_training)\n",
        "        x = tf.nn.leaky_relu(x)\n",
        "\n",
        "        x = self._out(x, training=for_training)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "UQumN6U21BLh"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Bq-MZlpZ13Pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(g, d, imgs, loss_function, g_optim, d_optim, for_training):\n",
        "    # generates a random image\n",
        "    noise = tf.random.normal([64,100])\n",
        "\n",
        "    with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
        "\n",
        "        # generate noise vector\n",
        "        generated_imgs = g(noise, training=for_training)\n",
        "\n",
        "        real_out = d(imgs, training=for_training)\n",
        "        fake_out = d(generated_imgs, training=for_training)\n",
        "\n",
        "        # calculating losses\n",
        "        g_loss = loss_function(tf.ones_like(fake_out), fake_out)\n",
        "        d_loss = loss_function(tf.ones_like(real_out)*0.9, real_out) + loss_function(tf.zeros_like(fake_out), fake_out)\n",
        "\n",
        "        # calculaing the gradients\n",
        "        gradients_g = g_tape.gradient(g_loss, g.trainable_variables)\n",
        "        gradients_d = d_tape.gradient(d_loss, d.trainable_variables)\n",
        "\n",
        "    # updating weights and biases\n",
        "    g_optim.apply_gradients(zip(gradients_g, g.trainable_variables))\n",
        "    d_optim.apply_gradients(zip(gradients_d, d.trainable_variables))\n",
        "\n",
        "    return g_loss, d_loss\n",
        "\n",
        "\n",
        "def test(gen, disc, test_data, loss_function, for_training):\n",
        "    # initializing lists for accuracys and loss\n",
        "    accuracy_aggregator = []\n",
        "    g_loss_aggregator = []\n",
        "    d_loss_aggregator = []\n",
        "\n",
        "    for imgs in test_data:\n",
        "        # forward step\n",
        "        noise = tf.random.normal([64,100])\n",
        "        generated_imgs = g(noise, training=for_training)\n",
        "        real_out = d(imgs, training=for_training)\n",
        "        fake_out = d(generated_imgs, training=for_training)\n",
        "\n",
        "        # calculating loss\n",
        "        g_loss = loss_function(tf.ones_like(fake_out), fake_out)\n",
        "        d_loss = loss_function(tf.ones_like(real_out)*0.9, real_out) + loss_function(tf.zeros_like(fake_out)*0.95, fake_out)\n",
        "\n",
        "        # add loss and accuracy to the lists\n",
        "        g_loss_aggregator.append(g_loss.numpy())\n",
        "        d_loss_aggregator.append(d_loss.numpy())\n",
        "\n",
        "    # calculate the mean of the loss and accuracy (for this epoch)\n",
        "    g_loss = tf.reduce_mean(g_loss_aggregator)\n",
        "    d_loss = tf.reduce_mean(d_loss_aggregator)\n",
        "\n",
        "    return g_loss, d_loss\n"
      ],
      "metadata": {
        "id": "3RYnG5fW15wJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classification(g, d, num_epochs, train_ds, valid_ds):\n",
        "    seed = tf.random.normal([64,100])\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    # initialize the loss: categorical cross entropy\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    lr = 0.0002\n",
        "\n",
        "    # optimizers for both models\n",
        "    g_optim = tf.keras.optimizers.Adam(lr,beta_1=0.5)\n",
        "    d_optim = tf.keras.optimizers.Adam(lr,beta_1=0.5)\n",
        "\n",
        "    # initialize lists for later visualization.\n",
        "    train_g_losses = []\n",
        "    valid_g_losses = []\n",
        "    train_d_losses = []\n",
        "    valid_d_losses = []\n",
        "\n",
        "    # testing on our valid_ds once before we begin\n",
        "    valid_g_loss, valid_d_loss = test(g, d, valid_ds, loss, for_training=False)\n",
        "    valid_g_losses.append(valid_g_loss)\n",
        "    valid_d_losses.append(valid_d_loss)\n",
        "\n",
        "    # Testing on our train_ds once before we begin\n",
        "    train_g_loss, train_d_loss = test(g, d, train_ds, loss, for_training=False)\n",
        "    train_g_losses.append(train_g_loss)\n",
        "    train_d_losses.append(train_d_loss)\n",
        "\n",
        "    # training our model for num_epochs epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f' starting with (validation set): g_loss {valid_g_losses[-1]} and d_loss {valid_d_losses[-1]}')\n",
        "        print(f' and (training set): g_loss {train_g_losses[-1]} and d_loss {train_d_losses[-1]}')\n",
        "        print(\"{}/{} epoches\".format(epoch, num_epochs))\n",
        "        \n",
        "        # training (and calculating loss while training)\n",
        "        epoch_g_loss_agg = []\n",
        "        epoch_d_loss_agg = []\n",
        "\n",
        "        for imgs in train_ds:\n",
        "            train_g_loss, train_d_loss = train_step(g, d, imgs, loss, g_optim, d_optim, for_training=True)\n",
        "            epoch_g_loss_agg.append(train_g_loss)\n",
        "            epoch_d_loss_agg.append(train_d_loss)\n",
        "\n",
        "        # track training loss\n",
        "        train_g_losses.append(tf.reduce_mean(epoch_g_loss_agg))\n",
        "        train_d_losses.append(tf.reduce_mean(epoch_d_loss_agg))\n",
        "\n",
        "        ## After i-th epoch plot image\n",
        "        if (epoch % 5) == 0:\n",
        "            fake_image = tf.reshape(g(seed, for_training=False), shape = (64,28,28))\n",
        "            plt.imshow(fake_image[10], cmap = \"gray\")\n",
        "            plt.show()\n",
        "\n",
        "        # testing our model in each epoch to track accuracy and loss on the validation set\n",
        "        valid_g_loss, valid_d_loss = test(g, d, valid_ds, loss, for_training=False)\n",
        "        valid_g_losses.append(valid_g_loss)\n",
        "        valid_d_losses.append(valid_d_loss)\n",
        "\n",
        "    results = [train_g_losses, valid_g_losses, train_d_losses, valid_d_losses]\n",
        "    return results, g, d"
      ],
      "metadata": {
        "id": "9yhtsKXs3HjX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(train_g_losses, valid_g_losses, train_d_losses, valid_d_losses):\n",
        "\n",
        "    fig, axs = plt.subplots(2, 1)\n",
        "    #fig.set_size_inches(13, 6)\n",
        "    # making a grid with subplots\n",
        "    for j in range(1):\n",
        "        axs[0].plot(train_g_l[j])\n",
        "        axs[0].plot(valid_g_l[j])\n",
        "        axs[1].plot(train_d_l[j])\n",
        "        axs[1].plot(valid_d_l[j])\n",
        "        axs[1].sharex(axs[0])\n",
        "\n",
        "    fig.legend([\" train_g_l\",\" valid_g_l\",\" train_d_l\",\" valid_d_l\"],loc=\"lower right\")\n",
        "    plt.xlabel(\"Training epoch\")\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "CyQUQOb33P6W"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "train_ds, valid_ds, test_ds = load_data()\n",
        "\n",
        "d = Descriminator()\n",
        "g = Generator()\n",
        "\n",
        "train_g_losses = []\n",
        "valid_g_losses = []\n",
        "train_d_losses = []\n",
        "valid_d_losses = []\n",
        "\n",
        "\n",
        "with tf.device('/device:gpu:0'):\n",
        "    # training the model\n",
        "    results, trained_g, trained_d = training(g, d, 10, train_ds, valid_ds)\n",
        "\n",
        "    # saving results for visualization\n",
        "    train_g_losses.append(results[0])\n",
        "    valid_g_losses.append(results[1])\n",
        "    train_d_losses.append(results[2])\n",
        "    valid_d_losses.append(results[3])\n",
        "\n",
        "    # testing the trained model\n",
        "    _, test_accuracy = test(trained_model, test_ds, tf.keras.losses.BinaryCrossentropy(), False)\n",
        "    print(\"Accuracy (test set):\", test_accuracy)\n",
        "\n",
        "# visualizing losses and accuracy\n",
        "visualize_results(train_g_losses, valid_g_losses, train_d_losses, valid_d_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-5mqwwtPnpJ",
        "outputId": "3f10425a-bd9e-4a20-de1b-d87d019bf960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141545 images to train on\n",
            " starting with (validation set): g_loss 0.6930728554725647 and d_loss 1.349241018295288\n",
            " and (training set): g_loss 0.6930713653564453 and d_loss 1.3491663932800293\n",
            "0/10 epoches\n"
          ]
        }
      ]
    }
  ]
}