{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homweork8_auto_encoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPqq8EMpGPIc"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3IAfVZUSv_np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "zoEBORBpYsEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_noisy(image, noise_level=1):\n",
        "    image = image + noise_level * tf.random.normal(mean=0, stddev=1, shape=image.shape, dtype=tf.dtypes.float32)\n",
        "    image = tf.clip_by_value(image, -1, 1)\n",
        "    return image"
      ],
      "metadata": {
        "id": "TqKJ1pS5Ytkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline(dataset, batching= True):\n",
        "    dataset = dataset.map(lambda image: image/128 - 1)\n",
        "    dataset = dataset.map(lambda image: tf.expand_dims(image, -1))\n",
        "    dataset = dataset.map(lambda image: (make_noisy(image), image)).cache()\n",
        "    if batching == True:\n",
        "      dataset = dataset.shuffle(1000)\n",
        "      dataset = dataset.batch(32)\n",
        "      dataset = dataset.prefetch(8)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "yFVLYhc3YwAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train))\n",
        "train_dataset = pipeline(train_dataset)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test))\n",
        "test_dataset = pipeline(test_dataset)"
      ],
      "metadata": {
        "id": "i65DV1SKY0Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (train_img,train_label), (test_img, test_label) = tf.keras.datasets.mnist.load_data()\n",
        "# print(train_img.shape)\n",
        "# print(train_label.shape)\n",
        "# print(test_img.shape)\n",
        "# print(test_label.shape)\n",
        "\n",
        "# train_ds = tf.data.Dataset.from_tensor_slices(train_img)\n",
        "# test_ds = tf.data.Dataset.from_tensor_slices(test_img)\n",
        "# print(\"\\nprinting infos after genetaring the data from tensorslicing \\n\", train_ds, test_ds)\n",
        "\n",
        "# # for training , data has still the img as data and labels as numbers\n",
        "# train_ds = train_ds.map(lambda img: (tf.cast(tf.expand_dims(img/255,-1),tf.float32)))\n",
        "# test_ds = test_ds.map(lambda img: tf.cast(tf.expand_dims(img/255,-1),tf.float32))\n",
        "\n",
        "# # creating the noise parameters to introduce to the data\n",
        "\n",
        "# # Create a random noise tensor and add it to the image tensor. You can introduce a\n",
        "# # hyperparameter to control how noisy your data will be. Make sure to keep the images within\n",
        "# # the right scale (between 0 and 1)\n",
        "# # 3You might want to make use of the functions tf.random.normal( ,mean=, stdev=, shape=)\n",
        "# # and tf.clip by value(, min=, max=)\n",
        "# shape = (28,28,1)\n",
        "# noise = tf.random.normal(\n",
        "#     shape, mean=0.0, stddev=0.3, dtype=tf.float32)\n",
        "\n",
        "\n",
        "# # tf.random.normal( ,mean=, stdev=, shape=)\n",
        "# print(\"noise\" , noise.shape, type(noise))\n",
        "\n",
        "\n",
        "# # for train dataset\n",
        "\n",
        "\n",
        "# train_ds = train_ds.map(lambda img: tf.math.add(img,noise))\n",
        "\n",
        "# train_ds = train_ds.map(lambda img: tf.clip_by_value(img, clip_value_min = 0.0, clip_value_max=1.0))\n",
        "\n",
        "# for eml in train_ds: \n",
        "#   print(eml.shape)\n",
        "#   arr = np.squeeze(eml)\n",
        "#   plt.imshow(arr)\n",
        "#   plt.show()\n",
        "#   break\n",
        "\n",
        "# # for test dataset\n",
        "\n",
        "# test_ds = test_ds.map(lambda img: tf.math.add(img,noise))\n",
        "\n",
        "# test_ds = test_ds.map(lambda img: tf.clip_by_value(img, clip_value_min = 0.0, clip_value_max=1.0))\n",
        "\n",
        "# for eml in test_ds: \n",
        "#   print(eml.shape)\n",
        "#   arr = np.squeeze(eml)\n",
        "#   plt.imshow(arr)\n",
        "#   plt.show()\n",
        "#   break\n",
        "\n",
        "#  # creating the pipeline\n",
        "#  # cache\n",
        "# train_ds= train_ds.cache()\n",
        "# test_ds = test_ds.cache() \n",
        "\n",
        "#  # shuffel\n",
        "# train_ds= train_ds.shuffle(1000)\n",
        "# test_ds = test_ds.shuffle(1000) \n",
        "\n",
        "#  # batch \n",
        "# train_ds= train_ds.batch(50)\n",
        "# test_ds = test_ds.batch(50) \n",
        "\n",
        "#  # prefetch \n",
        "# train_ds= train_ds.prefetch(8)\n",
        "# test_ds = test_ds.prefetch(8) \n",
        "  \n",
        "\n",
        "\n",
        "# print(train_ds)\n",
        "\n",
        "                                  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "sGNhb6D4kvwT",
        "outputId": "9ca85215-1556-47eb-acea-17fdae8a7ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n",
            "\n",
            "printing infos after genetaring the data from tensorslicing \n",
            " <TensorSliceDataset shapes: (28, 28), types: tf.uint8> <TensorSliceDataset shapes: (28, 28), types: tf.uint8>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-059fb5e7e803>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# for training , data has still the img as data and labels as numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtest_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Convolutional Autoencoder\n"
      ],
      "metadata": {
        "id": "sU4yeBwPDBl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense,Conv2DTranspose\n",
        "\n",
        "class Myencoder(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Myencoder, self).__init__() # 28x28x1\n",
        "        self.conv_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu) # 14x 14x 64\n",
        "        self.max_pool = tf.keras.layers.MaxPool2D(pool_size=(2,2) ,strides=(2, 2))# 7 x 7 x 64\n",
        "\n",
        "        self.conv_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu) # 14x 14x 64\n",
        "        self.max_pool_2 = tf.keras.layers.MaxPool2D(pool_size=(2,2) ,strides=(2, 2))# 7 x 7 x 64\n",
        "\n",
        "        self.flatten = tf.keras.layers.GlobalAveragePooling2D()\n",
        "\n",
        "        self.out_encoder = tf.keras.layers.Dense(10,activation=tf.nn.tanh)\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = self.conv_2(x)\n",
        "        x = self.max_pool_2(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.out_encoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "FY8pqMJwDAWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input  = tf.ones((1,28,28,1))\n",
        "model = Myencoder()\n",
        "model(input)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qWTMgMqKNh3",
        "outputId": "c086f6db-9c1d-4b28-b6c2-1d670ae8e1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"myencoder_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           multiple                  1280      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  multiple                 0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           multiple                  73792     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  multiple                 0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " global_average_pooling2d_1   multiple                 0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_2 (Dense)             multiple                  650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 75,722\n",
            "Trainable params: 75,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense,Conv2DTranspose\n",
        "\n",
        "class MyDEcoder(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(MyDEcoder, self).__init__() # 49x1\n",
        "        self.dense_1 = tf.keras.layers.Dense(7*7*3)\n",
        "        self.reshape = tf.keras.layers.Reshape((7,7,3))\n",
        "        self.transconv_1 = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=(2,2), strides=(2, 2),activation=tf.nn.relu) # 14x14x36\n",
        "        self.transconv_2 = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(2,2), strides=(2, 2),activation=tf.nn.relu) # 14x14x36 \n",
        " \n",
        "        self.out_DEcoder = tf.keras.layers.Conv2D(filters=1, kernel_size=(3,3), padding=\"same\", activation=tf.nn.tanh)  #28x28x1\n",
        "        \n",
        "        \n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "        x = self.dense_1(inputs)\n",
        "        x = self.reshape(x)\n",
        "\n",
        "        x = self.transconv_1(x)\n",
        "        x = self.transconv_2(x)\n",
        "\n",
        "        \n",
        "        x = self.out_DEcoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "XtfeFfy9Lp6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CompleteAutoEncoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CompleteAutoEncoder, self).__init__()\n",
        "        \n",
        "        \n",
        "        self.encoder = Myencoder()\n",
        "        \n",
        "        self.decoder = MyDEcoder()\n",
        "        \n",
        "        \n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "tObNcMt3RlPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5_Z0PnZ3P7z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input  = tf.ones((1,49))\n",
        "model_2 = MyDEcoder()\n",
        "print(model_2(input).shape)\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWh_5Bg3PyJo",
        "outputId": "a22867ac-a3c8-462b-9e4a-116983c2fa0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 28, 28, 1)\n",
            "Model: \"my_d_ecoder_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             multiple                  7350      \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         multiple                  0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  multiple                 1664      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  multiple                 32832     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           multiple                  577       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,423\n",
            "Trainable params: 42,423\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model, input, target, loss_function, optimizer):\n",
        "  # loss_object and optimizer_object are instances of respective tensorflow classes\n",
        "  with tf.GradientTape() as tape:\n",
        "    prediction = model(input)\n",
        "    loss = loss_function(target, prediction)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return loss\n",
        "\n",
        "def test(model, test_data, loss_function):\n",
        "  # test over complete test data\n",
        "\n",
        "  #test_accuracy_aggregator = []\n",
        "  test_loss_aggregator = []\n",
        "\n",
        "  for (input, target) in test_data:\n",
        "    prediction = model(input)\n",
        "    sample_test_loss = loss_function(target, prediction)\n",
        "   # sample_test_accuracy =  np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\n",
        "   # sample_test_accuracy = np.mean(sample_test_accuracy)\n",
        "    test_loss_aggregator.append(sample_test_loss.numpy())\n",
        "   # test_accuracy_aggregator.append(np.mean(sample_test_accuracy))\n",
        "\n",
        "  test_loss = tf.reduce_mean(test_loss_aggregator)\n",
        " # test_accuracy = tf.reduce_mean(test_accuracy_aggregator)\n",
        "\n",
        "  return test_loss#, test_accuracy"
      ],
      "metadata": {
        "id": "TopPac4-QPYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#For showcasing we only use a subset of the training and test data (generally use all of the available data!)\n",
        "# train_dataset = train_dataset.take(1000)\n",
        "# test_dataset = test_dataset.take(100)\n",
        "\n",
        "### Hyperparameters\n",
        "num_epochs = 20\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Initialize the model.\n",
        "model = CompleteAutoEncoder()\n",
        "# Initialize the loss: categorical cross entropy. Check out 'tf.keras.losses'.\n",
        "cross_entropy_loss = tf.keras.losses.MeanSquaredError()\n",
        "# Initialize the optimizer: SGD with default parameters. Check out 'tf.keras.optimizers'\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "# Initialize lists for later visualization.\n",
        "train_losses = []\n",
        "\n",
        "test_losses = []\n",
        "\n",
        "#testing once before we begin\n",
        "test_loss = test(model, test_dataset, cross_entropy_loss)\n",
        "test_losses.append(test_loss)\n",
        "\n",
        "#check how model performs on train data once before we begin\n",
        "train_loss = test(model, train_dataset, cross_entropy_loss)\n",
        "train_losses.append(train_loss)\n",
        "\n",
        "# We train for num_epochs epochs.\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch: {str(epoch)} starting with test loss {test_losses[-1]}')\n",
        "\n",
        "    #training (and checking in with training)\n",
        "    epoch_loss_agg = []\n",
        "    for input,target in train_dataset:\n",
        "        train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n",
        "        epoch_loss_agg.append(train_loss)\n",
        "    \n",
        "    #track training loss\n",
        "    train_losses.append(tf.reduce_mean(epoch_loss_agg))\n",
        "\n",
        "    #testing, so we can track accuracy and test loss\n",
        "    test_loss = test(model, test_dataset, cross_entropy_loss)\n",
        "    test_losses.append(test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD0CNVFCRTXU",
        "outputId": "1d20c4d9-4184-4197-b3b6-976671609e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 starting with test loss 0.9262027144432068\n",
            "Epoch: 1 starting with test loss 0.24398545920848846\n",
            "Epoch: 2 starting with test loss 0.22181732952594757\n",
            "Epoch: 3 starting with test loss 0.2048383504152298\n",
            "Epoch: 4 starting with test loss 0.19443568587303162\n",
            "Epoch: 5 starting with test loss 0.18958722054958344\n",
            "Epoch: 6 starting with test loss 0.18987281620502472\n",
            "Epoch: 7 starting with test loss 0.1801229566335678\n",
            "Epoch: 8 starting with test loss 0.18308623135089874\n",
            "Epoch: 9 starting with test loss 0.18156808614730835\n",
            "Epoch: 10 starting with test loss 0.17925989627838135\n",
            "Epoch: 11 starting with test loss 0.1765272617340088\n",
            "Epoch: 12 starting with test loss 0.17480111122131348\n",
            "Epoch: 13 starting with test loss 0.1757226437330246\n",
            "Epoch: 14 starting with test loss 0.1789248287677765\n",
            "Epoch: 15 starting with test loss 0.17702707648277283\n",
            "Epoch: 16 starting with test loss 0.1722611039876938\n",
            "Epoch: 17 starting with test loss 0.1731410175561905\n",
            "Epoch: 18 starting with test loss 0.170964777469635\n",
            "Epoch: 19 starting with test loss 0.1756698489189148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " def pipeline_viz(image):\n",
        "    image = image/128 - 1\n",
        "    image = make_noisy(image)\n",
        "    image = tf.expand_dims(image, -1)\n",
        "    image = tf.expand_dims(image, 0)\n",
        "\n",
        "    return image\n",
        "\n",
        "image = x_test[9]\n",
        "\n",
        "noisy = pipeline_viz(image)\n",
        "\n",
        "denoised = model(noisy)\n",
        "\n",
        "denoised = tf.squeeze(denoised)\n",
        "\n",
        "noisy = (tf.squeeze(noisy) + 1) / 2\n",
        "\n",
        "\n",
        "\n",
        "f, axarr = plt.subplots(1,2)\n",
        "axarr[0].imshow(noisy)\n",
        "axarr[1].imshow(denoised)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"train data\")\n",
        "\n",
        " def pipeline_viz(image):\n",
        "    image = image/128 - 1\n",
        "    image = make_noisy(image)\n",
        "    image = tf.expand_dims(image, -1)\n",
        "    image = tf.expand_dims(image, 0)\n",
        "\n",
        "    return image\n",
        "\n",
        "image = x_train[9]\n",
        "\n",
        "noisy = pipeline_viz(image)\n",
        "\n",
        "denoised = model(noisy)\n",
        "\n",
        "denoised = tf.squeeze(denoised)\n",
        "\n",
        "noisy = (tf.squeeze(noisy) + 1) / 2\n",
        "\n",
        "\n",
        "\n",
        "f, axarr = plt.subplots(1,2)\n",
        "axarr[0].imshow(noisy)\n",
        "axarr[1].imshow(denoised)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "Rg52d18Scs5u",
        "outputId": "16300f22-1f69-4f41-8d80-46a23c07bcfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdd3bc48990>"
            ]
          },
          "metadata": {},
          "execution_count": 160
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.min(image))\n",
        "print(np.max(image))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyv4ERK3eRRC",
        "outputId": "217411b7-3402-4e83-a2f2-e2430d15caac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image /255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "jkiwUEUmjvXJ",
        "outputId": "bfeecc24-cdbf-492a-842b-1154a6519f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fddb83d2e10>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nb0lBYpnn_V3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}